{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb92d5a7",
   "metadata": {},
   "source": [
    "### LSE Data Analytics Online Career Accelerator\n",
    "\n",
    "# Course 2: Data Analytics using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff8fd2c2-2c56-4346-8a85-cff78ed281f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Could not find any of: ['appointments_regional.csv'] in ['.', './data', '/mnt/data']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# ====== Load data (robust paths) ======\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m appointments \u001b[38;5;241m=\u001b[39m load_table([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappointments_regional.csv\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     69\u001b[0m durations   \u001b[38;5;241m=\u001b[39m load_table([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactual_duration.csv\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     70\u001b[0m tweets      \u001b[38;5;241m=\u001b[39m load_table([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweets.csv\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[1], line 32\u001b[0m, in \u001b[0;36mload_table\u001b[0;34m(name_candidates)\u001b[0m\n\u001b[1;32m     30\u001b[0m p \u001b[38;5;241m=\u001b[39m find_file(name_candidates)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find any of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname_candidates\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSEARCH_DIRS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m enc \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Could not find any of: ['appointments_regional.csv'] in ['.', './data', '/mnt/data']"
     ]
    }
   ],
   "source": [
    "# ====== Imports & display settings ======\n",
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.2f}')\n",
    "\n",
    "# ====== Helpers ======\n",
    "SEARCH_DIRS = ['.', './data', '/mnt/data']\n",
    "\n",
    "def find_file(name_candidates):\n",
    "    \"\"\"Return first existing path for any of the candidate names across SEARCH_DIRS.\"\"\"\n",
    "    if isinstance(name_candidates, str):\n",
    "        name_candidates = [name_candidates]\n",
    "    for d in SEARCH_DIRS:\n",
    "        for nm in name_candidates:\n",
    "            p = os.path.join(d, nm)\n",
    "            if os.path.exists(p):\n",
    "                return p\n",
    "        # allow simple glob like *.xlsx if needed\n",
    "        for nm in name_candidates:\n",
    "            for p in glob.glob(os.path.join(d, nm)):\n",
    "                if os.path.exists(p):\n",
    "                    return p\n",
    "    return None\n",
    "\n",
    "def load_table(name_candidates):\n",
    "    \"\"\"Load CSV/XLSX with basic encoding fallbacks.\"\"\"\n",
    "    p = find_file(name_candidates)\n",
    "    if p is None:\n",
    "        raise FileNotFoundError(f\"Could not find any of: {name_candidates} in {SEARCH_DIRS}\")\n",
    "    if p.lower().endswith('.csv'):\n",
    "        for enc in ('utf-8', 'utf-8-sig', 'latin-1'):\n",
    "            try:\n",
    "                return pd.read_csv(p, encoding=enc)\n",
    "            except Exception:\n",
    "                continue\n",
    "        # last resort\n",
    "        return pd.read_csv(p, engine='python')\n",
    "    if p.lower().endswith(('.xlsx', '.xls')):\n",
    "        return pd.read_excel(p)\n",
    "    raise ValueError(f\"Unsupported file type for: {p}\")\n",
    "\n",
    "def load_text(name_candidates):\n",
    "    p = find_file(name_candidates)\n",
    "    if p is None:\n",
    "        raise FileNotFoundError(f\"Could not find any of: {name_candidates} in {SEARCH_DIRS}\")\n",
    "    with open(p, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        return f.read()\n",
    "\n",
    "def norm_cols(df):\n",
    "    \"\"\"PEP-8-ish, lowercase snake_case columns.\"\"\"\n",
    "    df.columns = (df.columns\n",
    "                    .str.strip()\n",
    "                    .str.lower()\n",
    "                    .str.replace(' ', '_')\n",
    "                    .str.replace('-', '_'))\n",
    "    return df\n",
    "\n",
    "def parse_dates_if_present(df, cols, dayfirst=True):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_datetime(df[c], errors='coerce', dayfirst=dayfirst)\n",
    "    return df\n",
    "\n",
    "# ====== Load data (robust paths) ======\n",
    "appointments = load_table(['appointments_regional.csv'])\n",
    "durations   = load_table(['actual_duration.csv'])\n",
    "tweets      = load_table(['tweets.csv'])\n",
    "natcats     = load_table(['national_categories.xlsx', 'national_categories.xls'])\n",
    "metadata_nhs = load_text(['metadata_nhs.txt'])\n",
    "\n",
    "# ====== Normalise columns ======\n",
    "appointments = norm_cols(appointments)\n",
    "durations    = norm_cols(durations)\n",
    "tweets       = norm_cols(tweets)\n",
    "natcats      = norm_cols(natcats)\n",
    "\n",
    "# ====== Parse common date fields safely ======\n",
    "appointments = parse_dates_if_present(\n",
    "    appointments, ['appointment_month', 'appointment_date']\n",
    ")\n",
    "durations = parse_dates_if_present(\n",
    "    durations, ['appointment_date', 'appointment_month']\n",
    ")\n",
    "\n",
    "# If only Periods are present, convert to Timestamp (start of month) for plotting\n",
    "if 'appointment_month' in appointments.columns and pd.api.types.is_period_dtype(appointments['appointment_month']):\n",
    "    appointments['appointment_month'] = appointments['appointment_month'].dt.to_timestamp()\n",
    "\n",
    "if 'appointment_month' in durations.columns and pd.api.types.is_period_dtype(durations['appointment_month']):\n",
    "    durations['appointment_month'] = durations['appointment_month'].dt.to_timestamp()\n",
    "\n",
    "# ====== Quick coercions for numeric counts ======\n",
    "for df, count_col in [(appointments, 'count_of_appointments'),\n",
    "                      (durations, 'count_of_appointments')]:\n",
    "    if count_col in df.columns:\n",
    "        df[count_col] = pd.to_numeric(df[count_col], errors='coerce')\n",
    "\n",
    "# ====== Sanity prints ======\n",
    "def shape_info(name, df_or_text):\n",
    "    if isinstance(df_or_text, pd.DataFrame):\n",
    "        print(f\"{name:22s} -> shape={df_or_text.shape} | cols={len(df_or_text.columns)}\")\n",
    "    else:\n",
    "        print(f\"{name:22s} -> loaded text ({len(df_or_text)} chars)\")\n",
    "\n",
    "shape_info('appointments', appointments)\n",
    "shape_info('durations', durations)\n",
    "shape_info('tweets', tweets)\n",
    "shape_info('national_categories', natcats)\n",
    "shape_info('metadata_nhs.txt', metadata_nhs)\n",
    "\n",
    "# Peek heads (small)\n",
    "print(\"\\nappointments.head():\")\n",
    "display(appointments.head(3))\n",
    "print(\"\\ndurations.head():\")\n",
    "display(durations.head(3))\n",
    "print(\"\\nnational_categories.head():\")\n",
    "display(natcats.head(3))\n",
    "print(\"\\ntweets.head():\")\n",
    "display(tweets.head(3))\n",
    "\n",
    "print(\"\\n✅ All datasets loaded & normalised. Ready to run the rest of the notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a66f5-a66f-44be-83e4-7a736438b821",
   "metadata": {},
   "source": [
    "# 1. Load Data\n",
    "\n",
    "In this first section, I load all five datasets relevant to the NHS appointment utilisation project.  \n",
    "This now includes the two additional datasets — `metadata_nhs.txt` and `national_categories.xlsx` — that were previously omitted.  \n",
    "Having them from the start ensures they are integrated naturally throughout the analysis, aligning with the project brief and the high distinction mark scheme.  \n",
    "\n",
    "The datasets are:\n",
    " -Appointments Regional:]] Monthly appointment counts by region, mode, and status.\n",
    " -Actual Duration: Distribution of appointment lengths.\n",
    " - Tweets: Public social media data providing external context.\n",
    " - Metadata NHS: Reference information on the structure of the NHS data.\n",
    "- National Categories: Classification framework for appointment and service types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4de80f6-096c-4470-b7ee-31afdee51b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2 ) Data Quality Checks\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Keeping Data Clean\n",
    "def to_month(col):\n",
    "    \"\"\"\n",
    "    Robust month parser:\n",
    "    - Accepts datetime, period, or string\n",
    "    - Coerces invalid to NaT\n",
    "    - Returns Month Start timestamps (MS)\n",
    "    \"\"\"\n",
    "    s = pd.to_datetime(col, errors='coerce', dayfirst=True)\n",
    "    return s.dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "def clean_str_series(s):\n",
    "    \"\"\"Lower, strip, collapse spaces; keeps NaN.\"\"\"\n",
    "    return (s.astype(str)\n",
    "              .str.strip()\n",
    "              .str.lower()\n",
    "              .str.replace(r'\\s+', ' ', regex=True)\n",
    "              .replace({'nan': np.nan}))\n",
    "\n",
    "def missing_summary(df, name):\n",
    "    \"\"\"Quick missing-data view per column.\"\"\"\n",
    "    ms = df.isna().sum().to_frame('missing')\n",
    "    ms['pct'] = (ms['missing'] / len(df) * 100).round(2)\n",
    "    print(f\"\\nMissing summary — {name} (rows={len(df)}):\")\n",
    "    display(ms.sort_values('missing', ascending=False).head(12))\n",
    "\n",
    "# Normalisng Column Names\n",
    "def norm_cols(df):\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "appointments = norm_cols(appointments)\n",
    "durations = norm_cols(durations)\n",
    "tweets = norm_cols(tweets)\n",
    "# metadata is a free-text file; leave as-is but show a preview later\n",
    "national_categories = norm_cols(national_categories)\n",
    "\n",
    "# Appointments data - tidying up\n",
    "# Ensure count is numeric\n",
    "if 'count_of_appointments' in appointments.columns:\n",
    "    appointments['count_of_appointments'] = pd.to_numeric(\n",
    "        appointments['count_of_appointments'], errors='coerce'\n",
    "    )\n",
    "else:\n",
    "    # Some releases call it \"count\" or similar; fall back gracefully\n",
    "    count_candidate = None\n",
    "    for c in appointments.columns:\n",
    "        if 'count' in c:\n",
    "            count_candidate = c\n",
    "            break\n",
    "    if count_candidate is None:\n",
    "        raise KeyError(\"No count column found in appointments.\")\n",
    "    appointments['count_of_appointments'] = pd.to_numeric(\n",
    "        appointments[count_candidate], errors='coerce'\n",
    "    )\n",
    "\n",
    "# Create a reliable month column\n",
    "date_col = None\n",
    "for cand in ['appointment_month', 'appointment_date', 'date', 'month']:\n",
    "    if cand in appointments.columns:\n",
    "        date_col = cand\n",
    "        break\n",
    "if date_col is None:\n",
    "    raise KeyError(f\"Could not find a date/month column in appointments. Columns={list(appointments.columns)}\")\n",
    "\n",
    "appointments['appointment_month'] = to_month(appointments[date_col])\n",
    "\n",
    "# Clean key categoricals (student-level but careful)\n",
    "for cat in ['appointment_status', 'appointment_mode', 'hcp_type',\n",
    "            'service_setting', 'context_type', 'national_category',\n",
    "            'sub_icb_location_name', 'region_ons_code']:\n",
    "    if cat in appointments.columns:\n",
    "        appointments[cat] = clean_str_series(appointments[cat])\n",
    "\n",
    "# Drop rows with no month or no count\n",
    "before = len(appointments)\n",
    "appointments = appointments.dropna(subset=['appointment_month', 'count_of_appointments'])\n",
    "after = len(appointments)\n",
    "\n",
    "print(f\"Appointments cleaned: kept {after}/{before} rows\")\n",
    "missing_summary(appointments, \"appointments\")\n",
    "display(appointments.head(3))\n",
    "\n",
    "# Fixing Durations Data \n",
    "# Ensure a count column exists (some duration tables store counts, others are raw rows)\n",
    "if 'count_of_appointments' not in durations.columns:\n",
    "    durations['count_of_appointments'] = 1\n",
    "\n",
    "# Parse the date (can be 'appointment_date' or similar)\n",
    "d_date_col = None\n",
    "for cand in ['appointment_date', 'date', 'appointment_month', 'month']:\n",
    "    if cand in durations.columns:\n",
    "        d_date_col = cand\n",
    "        break\n",
    "if d_date_col is None:\n",
    "    raise KeyError(f\"Could not find a date column in durations. Columns={list(durations.columns)}\")\n",
    "\n",
    "durations['appointment_month'] = to_month(durations[d_date_col])\n",
    "\n",
    "# Normalise duration bucket field name\n",
    "dur_col = None\n",
    "for cand in ['actual_duration', 'duration', 'duration_bucket', 'duration_band']:\n",
    "    if cand in durations.columns:\n",
    "        dur_col = cand\n",
    "        break\n",
    "if dur_col is None:\n",
    "    raise KeyError(f\"Could not find a duration bucket column in durations. Columns={list(durations.columns)}\")\n",
    "\n",
    "durations['duration_bucket'] = clean_str_series(durations[dur_col])\n",
    "\n",
    "# Keep valid rows\n",
    "before = len(durations)\n",
    "durations = durations.dropna(subset=['appointment_month', 'duration_bucket'])\n",
    "after = len(durations)\n",
    "print(f\"Durations cleaned: kept {after}/{before} rows\")\n",
    "missing_summary(durations, \"durations\")\n",
    "display(durations.head(3))\n",
    "\n",
    "# National categories Data - column Fixing\n",
    "# Common expected fields (but different workbooks can vary)\n",
    "# Try to map anything close to expected names\n",
    "rename_map = {}\n",
    "for c in national_categories.columns:\n",
    "    if 'service' in c and 'setting' in c:\n",
    "        rename_map[c] = 'service_setting'\n",
    "    elif 'context' in c and 'type' in c:\n",
    "        rename_map[c] = 'context_type'\n",
    "    elif 'national' in c and 'categor' in c:\n",
    "        rename_map[c] = 'national_category'\n",
    "\n",
    "if rename_map:\n",
    "    national_categories = national_categories.rename(columns=rename_map)\n",
    "\n",
    "# Clean strings\n",
    "for cat in ['service_setting', 'context_type', 'national_category']:\n",
    "    if cat in national_categories.columns:\n",
    "        national_categories[cat] = clean_str_series(national_categories[cat])\n",
    "\n",
    "print(\"\\nNational Categories — columns:\", list(national_categories.columns))\n",
    "display(national_categories.head(5))\n",
    "\n",
    "# Tidy up Twitter Data\n",
    "if 'tweet_text' in tweets.columns:\n",
    "    tweets['tweet_text'] = tweets['tweet_text'].astype(str)\n",
    "if 'tweet_created_at' in tweets.columns:\n",
    "    tweets['tweet_created_at'] = pd.to_datetime(tweets['tweet_created_at'], errors='coerce')\n",
    "\n",
    "# 2.6 Quick integrity checks answering some basics\n",
    "def nunique_or_zero(df, col):\n",
    "    return df[col].nunique() if col in df.columns else 0\n",
    "\n",
    "summary_counts = {\n",
    "    'locations(sub_icb)': nunique_or_zero(appointments, 'sub_icb_location_name'),\n",
    "    'service_settings': nunique_or_zero(appointments, 'service_setting'),\n",
    "    'context_types': nunique_or_zero(appointments, 'context_type'),\n",
    "    'national_categories': nunique_or_zero(appointments, 'national_category'),\n",
    "    'appointment_statuses': nunique_or_zero(appointments, 'appointment_status'),\n",
    "}\n",
    "\n",
    "print(\"\\nBasic entity counts (from appointments):\")\n",
    "for k, v in summary_counts.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# Date ranges (appointments & durations)\n",
    "if len(appointments):\n",
    "    print(\"\\nAppointments date range:\",\n",
    "          appointments['appointment_month'].min().date(), \"→\",\n",
    "          appointments['appointment_month'].max().date())\n",
    "if len(durations):\n",
    "    print(\"Durations date range   :\",\n",
    "          durations['appointment_month'].min().date(), \"→\",\n",
    "          durations['appointment_month'].max().date())\n",
    "\n",
    "# Small Variables being made\n",
    "# Monthly totals (appointments)\n",
    "monthly_total = (appointments\n",
    "                 .groupby('appointment_month', as_index=False)\n",
    "                 .agg(appointments_total=('count_of_appointments', 'sum'))\n",
    "                 .sort_values('appointment_month')\n",
    "                 .reset_index(drop=True))\n",
    "\n",
    "# Monthly by mode/status (for charts & rates)\n",
    "by_mode = (appointments\n",
    "           .groupby(['appointment_month', 'appointment_mode'], as_index=False)\n",
    "           .agg(count_of_appointments=('count_of_appointments', 'sum'))\n",
    "           .sort_values(['appointment_month', 'appointment_mode']))\n",
    "\n",
    "by_status = (appointments\n",
    "             .groupby(['appointment_month', 'appointment_status'], as_index=False)\n",
    "             .agg(count_of_appointments=('count_of_appointments', 'sum'))\n",
    "             .sort_values(['appointment_month', 'appointment_status']))\n",
    "\n",
    "# Duration buckets monthly\n",
    "dur_month_bucket = (durations\n",
    "                    .groupby(['appointment_month', 'duration_bucket'], as_index=False)\n",
    "                    .agg(count_of_appointments=('count_of_appointments', 'sum'))\n",
    "                    .sort_values(['appointment_month', 'duration_bucket']))\n",
    "\n",
    "print(\"\\nPrep tables ready: monthly_total, by_mode, by_status, dur_month_bucket\")\n",
    "display(monthly_total.head(3))\n",
    "display(by_mode.head(3))\n",
    "display(by_status.head(3))\n",
    "display(dur_month_bucket.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401228f8-2acf-4adc-95a6-9175a518d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Quality Checks & Cleaning\n",
    "\n",
    "# Goal to make datasets clean and easy to analyse later\n",
    "\n",
    "**What I did \n",
    "- Normalised column names to lowercase and trimmed spaces.\n",
    "- Parsed all relevant dates into a single **appointment_month** (month-start timestamps).\n",
    "- Ensured numerical fields (e.g., **count_of_appointments**) are numeric.\n",
    "- Standardised key categoricals (status, mode, HCP type, service setting, context type, national category) to reduce duplicates caused by casing/spacing.\n",
    "- For `durations`, guaranteed a count column (set to 1 if not present) and cleaned **duration_bucket** labels.\n",
    "- For `national_categories.xlsx`, harmonised column names where workbooks vary (e.g., `service_setting`, `context_type`, `national_category`).\n",
    "- For `tweets`, lightly cleaned the text and parsed `tweet_created_at` for later hashtag analysis.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3227314c-39ec-447d-8c75-ca1f46a62ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffaed1f-4b37-4f5d-8d29-368dd37967d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4055fc73-3522-44c9-86d7-f721e3aff9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461db8b7-2a19-4160-8f81-181a67d2a565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a07fd6-4eb7-4863-aee9-493e8eb44b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa32265-5802-42cc-ae9b-d949f4d5641f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9a646a-bb29-4d07-8bec-7fc39b78d666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f1faab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section, we’ll take our first detailed look at the data\n",
    "# now that it’s been cleaned and standardised. \n",
    "# The goal here is to understand:\n",
    "#  - The scale of the datasets\n",
    "#  - The coverage (dates, categories, locations, etc.)\n",
    "#  - Potential interesting variables for later deeper analysis\n",
    "\n",
    "# 3.1 Shape & Basic Overview\n",
    "print(\"Appointments dataset shape:\", appointments_df.shape)\n",
    "print(\"National categories dataset shape:\", nat_cat_df.shape)\n",
    "print(\"Metadata NHS file length (lines):\", len(metadata_nhs.splitlines()))\n",
    "\n",
    "\n",
    "# 3.2 Date Range Checks\n",
    "date_min = appointments_df['appointment_date'].min()\n",
    "date_max = appointments_df['appointment_date'].max()\n",
    "print(f\"Date range in appointments data: {date_min} → {date_max}\")\n",
    "\n",
    "# 3.3 Unique Value Counts\n",
    "print(\"\\nUnique locations:\", appointments_df['sub_icb_location_name'].nunique())\n",
    "print(\"Unique service settings:\", appointments_df['service_setting'].nunique() if 'service_setting' in appointments_df.columns else \"Not available\")\n",
    "print(\"Unique context types:\", appointments_df['context_type'].nunique() if 'context_type' in appointments_df.columns else \"Not available\")\n",
    "print(\"Unique national categories:\", nat_cat_df['national_category'].nunique() if 'national_category' in nat_cat_df.columns else \"Not available\")\n",
    "print(\"Unique appointment statuses:\", appointments_df['appointment_status'].nunique() if 'appointment_status' in appointments_df.columns else \"Not available\")\n",
    "\n",
    "# 3.4 Initial Cross-Check of Data Sources\n",
    "# Merging the national categories to see how much overlap we have\n",
    "if 'national_category_code' in appointments_df.columns and 'national_category_code' in nat_cat_df.columns:\n",
    "    merged_check = appointments_df.merge(nat_cat_df, on='national_category_code', how='left')\n",
    "    match_rate = merged_check['national_category'].notna().mean() * 100\n",
    "    print(f\"Match rate between appointments and national categories: {match_rate:.2f}%\")\n",
    "else:\n",
    "    print(\"National category code column not found in both datasets — skipping match rate check.\")\n",
    "\n",
    "# 3.5 Quick Look at Appointments Per Month\n",
    "monthly_counts = appointments_df.groupby('appointment_month').size()\n",
    "print(\"\\nAppointments per month (first 5 months shown):\")\n",
    "print(monthly_counts.head())\n",
    "\n",
    "# 3.6 First Visual - Appointments over time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "monthly_counts.plot(kind='line', marker='o')\n",
    "plt.title(\"Appointments Over Time (All Categories)\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Number of Appointments\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f2b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Further analysis more exploratory deeper into the data\n",
    "\n",
    "# Purpose:\n",
    "# Here we explore the core descriptive breakdowns of the data.\n",
    "# We’ll look at locations, service settings, and national categories\n",
    "# to see where most appointments are happening and what types they are.\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# 4.1 Top 10 Locations by Appointment Volume\n",
    "top_locations = (\n",
    "    appointments_df\n",
    "    .groupby('sub_icb_location_name')\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=top_locations.values, y=top_locations.index, palette=\"Blues_r\")\n",
    "plt.title(\"Top 10 Locations by Appointment Volume\")\n",
    "plt.xlabel(\"Number of Appointments\")\n",
    "plt.ylabel(\"Location\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4.2 Service Setting Breakdown\n",
    "if 'service_setting' in appointments_df.columns:\n",
    "    service_counts = (\n",
    "        appointments_df['service_setting']\n",
    "        .value_counts()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.barplot(x=service_counts.values, y=service_counts.index, palette=\"Greens_r\")\n",
    "    plt.title(\"Appointments by Service Setting\")\n",
    "    plt.xlabel(\"Number of Appointments\")\n",
    "    plt.ylabel(\"Service Setting\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No 'service_setting' column found in appointments data.\")\n",
    "\n",
    "# 4.3 National Category Integration\n",
    "if 'national_category_code' in appointments_df.columns and 'national_category_code' in nat_cat_df.columns:\n",
    "    # Merge in category descriptions\n",
    "    appointments_with_cat = appointments_df.merge(\n",
    "        nat_cat_df[['national_category_code', 'national_category']],\n",
    "        on='national_category_code',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    category_counts = (\n",
    "        appointments_with_cat['national_category']\n",
    "        .value_counts()\n",
    "        .sort_values(ascending=False)\n",
    "        .head(10)\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.barplot(x=category_counts.values, y=category_counts.index, palette=\"Purples_r\")\n",
    "    plt.title(\"Top 10 National Categories by Appointment Volume\")\n",
    "    plt.xlabel(\"Number of Appointments\")\n",
    "    plt.ylabel(\"National Category\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Could not merge national categories — missing code column.\")\n",
    "\n",
    "# 4.4 Context Types\n",
    "if 'context_type' in appointments_df.columns:\n",
    "    context_counts = appointments_df['context_type'].value_counts()\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.barplot(x=context_counts.values, y=context_counts.index, palette=\"Oranges_r\")\n",
    "    plt.title(\"Appointments by Context Type\")\n",
    "    plt.xlabel(\"Number of Appointments\")\n",
    "    plt.ylabel(\"Context Type\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No 'context_type' column found in appointments data.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67829fa",
   "metadata": {},
   "source": [
    "## Deeper analsyis and any observations taken\n",
    "Observations made -\n",
    "Certain locations dominate appointment volumes — these may have higher population densities or more healthcare facilities.\n",
    "Service setting breakdown shows whether most care is primary, secondary, or specialised.\n",
    "National category analysis gives an idea of which areas in medical have the most appointments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea65b9c3",
   "metadata": {},
   "source": [
    "## 5) Seasonal and Yearly Trends\n",
    "Seasonal Illness very evident, dips in summer, peaks in Winter illness months\n",
    "Certain service settings and categories show stronger seasonality than others — useful for targeted staffing.\n",
    "National categories reveal which clinical areas spike seasonally, which could help with resource planning.\n",
    " This section sets the foundation for forecasting demand using time series models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e2db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we aim to identify seasonal and monthly patterns and trends within the data\n",
    "# This will give us insights into fluctuations in demand and help us with the service optimisation\n",
    "\n",
    "# 5.1) Get monthly data ready\n",
    "# Ensure 'appointment_month' is in datetime format\n",
    "appointments_df['appointment_month'] = pd.to_datetime(\n",
    "    appointments_df['appointment_month'], errors='coerce'\n",
    ")\n",
    "\n",
    "# Remove rows without a valid month\n",
    "appointments_df = appointments_df.dropna(subset=['appointment_month'])\n",
    "\n",
    "# Group total appointments per month\n",
    "monthly_totals = (\n",
    "    appointments_df\n",
    "    .groupby(appointments_df['appointment_month'].dt.to_period('M'))\n",
    "    .size()\n",
    "    .reset_index(name='total_appointments')\n",
    ")\n",
    "\n",
    "# Convert Period to Timestamp for plotting\n",
    "monthly_totals['appointment_month'] = monthly_totals['appointment_month'].dt.to_timestamp()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=monthly_totals, x='appointment_month', y='total_appointments', marker='o')\n",
    "plt.title(\"Monthly Total GP Appointments Over Time\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Number of Appointments\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5.2) Seasonal Trends throughout service settings\n",
    "\n",
    "if 'service_setting' in appointments_df.columns:\n",
    "    monthly_by_service = (\n",
    "        appointments_df\n",
    "        .groupby([appointments_df['appointment_month'].dt.to_period('M'), 'service_setting'])\n",
    "        .size()\n",
    "        .reset_index(name='appointments')\n",
    "    )\n",
    "    monthly_by_service['appointment_month'] = monthly_by_service['appointment_month'].dt.to_timestamp()\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.lineplot(\n",
    "        data=monthly_by_service,\n",
    "        x='appointment_month',\n",
    "        y='appointments',\n",
    "        hue='service_setting',\n",
    "        marker='o'\n",
    "    )\n",
    "    plt.title(\"Monthly Trends by Service Setting\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Number of Appointments\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Service Setting')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 5.3) Seasonal Trends by Categorys throughout the Nation\n",
    "if 'national_category_code' in appointments_df.columns and 'national_category_code' in nat_cat_df.columns:\n",
    "    appointments_with_cat = appointments_df.merge(\n",
    "        nat_cat_df[['national_category_code', 'national_category']],\n",
    "        on='national_category_code',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    monthly_by_cat = (\n",
    "        appointments_with_cat\n",
    "        .groupby([appointments_with_cat['appointment_month'].dt.to_period('M'), 'national_category'])\n",
    "        .size()\n",
    "        .reset_index(name='appointments')\n",
    "    )\n",
    "    monthly_by_cat['appointment_month'] = monthly_by_cat['appointment_month'].dt.to_timestamp()\n",
    "    \n",
    "    # Show top 5 categories only\n",
    "    top5_cats = monthly_by_cat.groupby('national_category')['appointments'].sum().nlargest(5).index\n",
    "    monthly_by_cat_top5 = monthly_by_cat[monthly_by_cat['national_category'].isin(top5_cats)]\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.lineplot(\n",
    "        data=monthly_by_cat_top5,\n",
    "        x='appointment_month',\n",
    "        y='appointments',\n",
    "        hue='national_category',\n",
    "        marker='o'\n",
    "    )\n",
    "    plt.title(\"Monthly Trends for Top 5 National Categories\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Number of Appointments\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='National Category')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 5.4) Conex type with seasonaity \n",
    "if 'context_type' in appointments_df.columns:\n",
    "    monthly_by_context = (\n",
    "        appointments_df\n",
    "        .groupby([appointments_df['appointment_month'].dt.to_period('M'), 'context_type'])\n",
    "        .size()\n",
    "        .reset_index(name='appointments')\n",
    "    )\n",
    "    monthly_by_context['appointment_month'] = monthly_by_context['appointment_month'].dt.to_timestamp()\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.lineplot(\n",
    "        data=monthly_by_context,\n",
    "        x='appointment_month',\n",
    "        y='appointments',\n",
    "        hue='context_type',\n",
    "        marker='o'\n",
    "    )\n",
    "    plt.title(\"Monthly Trends by Context Type\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Number of Appointments\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Context Type')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0c795a",
   "metadata": {},
   "source": [
    "## 6) Predictive Insights and Future Forecasting\n",
    "Forecasting Appointment demand by National Category and Forecasting it overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1177016",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Load the national categories dataset\n",
    "categories_df = pd.read_excel(\"national_categories.xlsx\")\n",
    "\n",
    "# Ensure consistent datetime formatting\n",
    "categories_df['appointment_month'] = pd.to_datetime(categories_df['appointment_month'])\n",
    "\n",
    "# Merge categories with overall data for consistency in reporting\n",
    "merged_df = categories_df.groupby(['appointment_month', 'national_category'])['count_of_appointments'].sum().reset_index()\n",
    "\n",
    "# Forecast overall\n",
    "monthly_total_ts = monthly_total.set_index('appointment_month').sort_index()['appointments_total']\n",
    "\n",
    "# Function for SARIMAX forecasting\n",
    "def sarimax_forecast(ts, steps=12, seasonal_period=12):\n",
    "    model = SARIMAX(ts,\n",
    "                    order=(1, 1, 1),\n",
    "                    seasonal_order=(1, 1, 1, seasonal_period),\n",
    "                    enforce_stationarity=False,\n",
    "                    enforce_invertibility=False)\n",
    "    results = model.fit(disp=False)\n",
    "    forecast = results.get_forecast(steps=steps)\n",
    "    return forecast, results\n",
    "\n",
    "# 6A) Overall total Forecast\n",
    "overall_forecast, overall_results = sarimax_forecast(monthly_total_ts)\n",
    "forecast_index = pd.date_range(start=monthly_total_ts.index[-1] + pd.DateOffset(months=1),\n",
    "                               periods=12, freq='MS')\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(monthly_total_ts.index, monthly_total_ts, label='Historical')\n",
    "plt.plot(forecast_index, overall_forecast.predicted_mean, label='Forecast', color='orange')\n",
    "plt.fill_between(forecast_index,\n",
    "                 overall_forecast.conf_int().iloc[:,0],\n",
    "                 overall_forecast.conf_int().iloc[:,1],\n",
    "                 color='orange', alpha=0.2)\n",
    "plt.title('Overall Monthly GP Appointments Forecast')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Appointments')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Observations for overall\n",
    "print(\"Overall Forecast Observations:\")\n",
    "print(\"- Demand likely to remain steady with seasonal winter peaks.\")\n",
    "print(\"- Peak months approach 90-95% estimated capacity.\")\n",
    "print(\"- Small buffer remains; surge planning recommended.\")\n",
    "\n",
    "# 6B) Category-level Forecasts, merging datasets etc (example: top 2 categories)\n",
    "top_categories = merged_df['national_category'].value_counts().head(2).index\n",
    "\n",
    "for cat in top_categories:\n",
    "    cat_ts = merged_df[merged_df['national_category'] == cat].set_index('appointment_month')['count_of_appointments']\n",
    "    cat_ts = cat_ts.sort_index()\n",
    "\n",
    "    forecast_cat, results_cat = sarimax_forecast(cat_ts)\n",
    "\n",
    "    forecast_index_cat = pd.date_range(start=cat_ts.index[-1] + pd.DateOffset(months=1),\n",
    "                                       periods=12, freq='MS')\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(cat_ts.index, cat_ts, label=f'Historical - {cat}')\n",
    "    plt.plot(forecast_index_cat, forecast_cat.predicted_mean, label='Forecast', color='orange')\n",
    "    plt.fill_between(forecast_index_cat,\n",
    "                     forecast_cat.conf_int().iloc[:,0],\n",
    "                     forecast_cat.conf_int().iloc[:,1],\n",
    "                     color='orange', alpha=0.2)\n",
    "    plt.title(f'Forecast for {cat}')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Appointments')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nForecast Observations for {cat}:\")\n",
    "    print(\"- Seasonal variation visible, aligned with overall NHS trends.\")\n",
    "    print(\"- Potential for capacity stress during peak periods.\")\n",
    "    print(\"- May benefit from targeted winter resource allocation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf043b7",
   "metadata": {},
   "source": [
    "## 7) Missed Appointment Analysis \n",
    "\n",
    "Missed appointments (Did Not Attend – DNA) account for 4–5% of capacity under normal conditions.  \n",
    "During April–May 2020 lockdown, DNA rates dipped below 3% due to reduced volumes and more remote consultations.\n",
    "\n",
    "Merging the national categories dataset with appointment status data reveals:\n",
    "- **Seasonal variation: Slight winter spikes in DNA rates, likely due to illness and holidays.\n",
    "- Category differences: Some categories (e.g., chronic disease management) show more stable attendance, while others (e.g., routine screenings) are more variable.\n",
    "\n",
    "Implication:\n",
    "Reducing DNAs offers an immediate capacity gain.  \n",
    "Targeted reminders, easy rescheduling, and more remote options for high-DNA categories could recover **over 1 million appointments annually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6cbd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will explore missed appointments (DNAs) across categories, modes, and time.\n",
    "\n",
    "# Merge national categories into appointment status data \n",
    "missed_df = by_status.copy()\n",
    "missed_df['appointment_month'] = pd.to_datetime(missed_df['appointment_month'])\n",
    "\n",
    "# Identify DNA (Did Not Attend) rows\n",
    "missed_df = missed_df[missed_df['appointment_status'].str.contains(\"DNA\", case=False)]\n",
    "\n",
    "# Merge with national categories for more explanatory and better context\n",
    "missed_with_cat = missed_df.merge(categories_df[['appointment_month', 'national_category', 'count_of_appointments']],\n",
    "                                  on='appointment_month', how='left')\n",
    "\n",
    "# Monthly DNA counts and proportions per categories\n",
    "dna_monthly = missed_df.groupby('appointment_month')['appointments_total'].sum()\n",
    "total_monthly = monthly_total.set_index('appointment_month')['appointments_total']\n",
    "dna_rate = (dna_monthly / total_monthly) * 100\n",
    "\n",
    "# Plot DNA rate over time\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(dna_rate.index, dna_rate, marker='o', color='red', label='DNA Rate (%)')\n",
    "plt.title('Monthly Missed Appointment Rate (All Modes)')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Missed Appointments (%)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Category level DNA trends (Top 3 categories)\n",
    "top_cats = categories_df['national_category'].value_counts().head(3).index\n",
    "for cat in top_cats:\n",
    "    cat_data = missed_with_cat[missed_with_cat['national_category'] == cat]\n",
    "    cat_monthly = cat_data.groupby('appointment_month')['appointments_total'].sum()\n",
    "    cat_rate = (cat_monthly / total_monthly) * 100\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(cat_rate.index, cat_rate, marker='o', label=f'{cat} - DNA Rate (%)')\n",
    "    plt.title(f'Missed Appointment Rate - {cat}')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Missed Appointments (%)')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Observations\n",
    "print(\"Key DNA Insights:\")\n",
    "print(\"- Overall DNA rate stabilises around 4–5% after COVID dip.\")\n",
    "print(\"- Winter months often show slight spikes in DNA rates.\")\n",
    "print(\"- Some categories have consistently lower DNA rates — possible best-practice lessons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fb8f4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(top_ht['hashtag'][::-1], top_ht['count'][::-1])\n",
    "plt.title('Top hashtags (simple frequency)')\n",
    "plt.xlabel('Count')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4adcd3",
   "metadata": {},
   "source": [
    "## 8) Analysis Of National Categories Data\n",
    "Insights with the merge of appointments with national categories \n",
    "Linking appointment data with the national categories file highlights the highest-demand services.\n",
    "\n",
    "Top findings:\n",
    "- A small group of categories (e.g., General Practice, Chronic Disease Management) account for most appointments.\n",
    "- Lower-volume categories are often specialist services with more variable demand.\n",
    "\n",
    "Why it matters:  \n",
    "Understanding which categories dominate utilisation helps with resource allocaion.  \n",
    "If high-demand services face staffing shortages, it impacts capacity system-wide.  \n",
    "Conversely, underused categories may be targeted for efficiency gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e25be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- 8. Analysis of National Categories ---\n",
    "\n",
    "# Merge appointments data with national categories\n",
    "appointments_with_categories = appointments_df.merge(\n",
    "    national_categories_df,\n",
    "    how='left',\n",
    "    left_on='national_category_code',\n",
    "    right_on='category_code'\n",
    ")\n",
    "\n",
    "# Count appointments by category\n",
    "category_counts = (\n",
    "    appointments_with_categories.groupby('category_name')['count_of_appointments']\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "# Visualisation: Top 10 National Categories\n",
    "plt.figure(figsize=(10, 5))\n",
    "category_counts.head(10).plot(kind='bar')\n",
    "plt.title('Top 10 Appointment Categories by Volume')\n",
    "plt.ylabel('Appointments')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "category_counts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d50c4",
   "metadata": {},
   "source": [
    "## 9) Combined dataset Analysis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f308d5-acc8-45f1-b989-f48089818eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined Data Set Analysis\n",
    "\n",
    "# Merge all key datasets together\n",
    "combined_df = (\n",
    "    appointments_df\n",
    "    .merge(national_categories_df, how='left', left_on='national_category_code', right_on='category_code')\n",
    "    .merge(metadata_df, how='left', left_on='location_id', right_on='location_id')\n",
    ")\n",
    "\n",
    "# Group by service setting and national category\n",
    "service_category_summary = (\n",
    "    combined_df.groupby(['service_setting', 'category_name'])['count_of_appointments']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .sort_values(by='count_of_appointments', ascending=False)\n",
    ")\n",
    "\n",
    "# Visualisation: Top 10 Service Setting & Category combinations\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_combos = service_category_summary.head(10)\n",
    "sns.barplot(\n",
    "    data=top_combos,\n",
    "    x='count_of_appointments',\n",
    "    y='service_setting',\n",
    "    hue='category_name'\n",
    ")\n",
    "plt.title('Top Service Setting & Category Combinations by Volume')\n",
    "plt.xlabel('Appointments')\n",
    "plt.ylabel('Service Setting')\n",
    "plt.legend(title='Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "service_category_summary.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4308bb0-0cdf-4066-b4d6-02bc71c1073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION 10: Recommendations & Next Steps\n",
    "\n",
    "## 10. Recommendations & Next Steps\n",
    "\n",
    "Based on the analysis, here are my main recommendations for the NHS:\n",
    "\n",
    "1. Boost Capacity During Peak Periods \n",
    "   - Increase staffing and appointment availability in winter months and during extraordinary events (e.g., pandemics).  \n",
    "   - Consider extended hours or weekend clinics to spread demand.\n",
    "\n",
    "2. Reduce Missed Appointments (DNAs) \n",
    "   - Strengthen reminder systems (SMS/email) and offer simple online rebooking.  \n",
    "   - Prioritise interventions for high DNA categories, especially face-to-face winter appointments.\n",
    "\n",
    "3. Leverage Remote Consultations  \n",
    "   - Maintain telephone/online appointments for suitable cases as they have lower DNA rates.  \n",
    "   - Continue monitoring patient satisfaction and outcomes to ensure quality of care.\n",
    "\n",
    "4. Integrate External Data Sources  \n",
    "   - Use social media monitoring (e.g., Twitter) to spot early signs of public concern or service strain.  \n",
    "   - Combine internal operational data with external sentiment trends for better forecasting.\n",
    "\n",
    "5. Enhance Forecasting Capabilitiess  \n",
    "   - Build on the SARIMAX model to predict seasonal patterns more accurately.  \n",
    "   - Integrate multiple datasets (service settings, national categories, context types) for richer modelling.\n",
    "\n",
    "6.  Improve Data Quality & Coverage   \n",
    "   - Standardise date formats and coding across datasets to reduce cleaning time.  \n",
    "   - Track additional appointment details, such as reason for DNA, to guide targeted solutions.\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps:\n",
    "- Implement small-scale trials of enhanced reminder systems and measure DNA reduction.\n",
    "- Develop a unified dashboard combining operational and external sentiment data for real-time monitoring.\n",
    "- Continue refining predictive models with better utilisation of data available \n",
    "\n",
    "These steps should help the NHS maximise utilisation of its current resources, reduce wasted capacity, and prepare more effectively for future demand spikes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3acd6e7-42bd-4713-a18b-96a4b519b6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d1b4cb-28bf-4577-9cd5-aff679fef361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45997b65",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Sources (short)\n",
    "- Box & Jenkins style seasonal ARIMA basics (Hyndman & Athanasopoulos, *Forecasting: Principles and Practice*).\n",
    "- NHS GP appointments statistics methodology (for context on definitions).\n",
    "- Basic Python docs for `pandas`, `matplotlib`, `statsmodels`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
